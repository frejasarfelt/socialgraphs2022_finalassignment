multiple view geometry  image feature detection and description  ranging  3d cloud  processing  object pose estimation  state estimation  classification  visual odometry  slam  object detection  the exercise part consists of introductory exercises and a project solved in teams lectures  exercises  group work and homework the course familiarizes participants with the theory and practical applications of perception for autonomous systems  the aim is to enable students to transform sensory input from a variety of imaging and 3d sensors into more abstract descriptions of the observed scene  thus  such techniques will allow autonomous systems to perceive their environment and act within it or interact with it  the course will provide both the mathematical descriptions and programming tools to implement such perception techniques  finally  the aim is to enable the participants to use the taught concepts and tools to further develop either embodied  e g  robotic  or intangible  e g  software agent  autonomous systems 