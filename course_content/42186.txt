this course will have lectures with slides and with laboratory work using interactive tools  jupyter notebooks in python using a probabilistic programming language like pyro or stan   students will always work manually each module  during and after the theoretical class  to assimilate new concepts  it is designed to be incremental  and strongly supported with practice    modules     review of basics   random variable  probability distributions  bayes theorem    probabilistic graphical models foundations   bayesian networks  factorization    d separation  conditional independence   probabilistic graphical models   generative models  representing your own problem    different models   regression  classification  hierarchical models  temporal models  topic models  gaussian processes   inference   exact inference    inference   markov chain monte carlo    inference   variational inference   advanced topicslectures and practical laboratories with ipython notebook model based machine learning   john winn  christopher bishop  thomas diethe   http   www mbmlbook com excerpts from  list may be extended    pattern recognition and machine learning   christopher bishop  probabilistic graphical models   daphne koller and nir friedmanthis course is designed for engineers  systems analysts  statisticians or related professionals looking to perform advanced data analysis in their future research or practice  model based machine learning corresponds to a class of algorithms  called probabilistic graphical models  pgms   that allows the combination of domain knowledge with data driven methods  in a very simple way  it expects two key ingredients  fundamental statistics and probability  e g  42585 business analytics   knowledge of computer programming  e g  python  r  matlab  julia  c    java     while machine learning has plenty of algorithms  e g  neural networks  gaussian processes  support vector machines  decision trees  etc   that have the benefit of being  push button  solutions  they are generally very hardly adaptable beyond the original design  our task becomes about transforming our problem and data to fit each individual algorithm  many times  we drop relevant information  e g  known relationship between 2 variables  different noise distributions in input variables   and our results may suffer from it    pgms allow us to include prior knowledge  parametric and non parametric  sub  models  and uncertainty about inputs and parameters  they are perfect to combine different types of data  and  in the past few years  a growing community has developed tools for pgms  that simplify its design and inference process  together with deep learning  pgms belong to the forefront of machine learning and data mining research  essential to process big and small data    while this course is  in nature  about methodology  it is grounded on a sequence of example applications  mostly focused on transport system problems 